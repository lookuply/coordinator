"""Mark non-EU URLs as SKIPPED.

This script reads URL IDs from /tmp/non_eu_urls.txt (generated by analyze_url_languages.py)
and marks them as SKIPPED in the database with an appropriate error message.

This is a cleanup operation to remove non-EU language URLs that were discovered before
the language filtering feature was implemented.

Usage:
    # First, run the analysis script:
    python scripts/analyze_url_languages.py

    # Then, run this script to mark non-EU URLs as SKIPPED:
    python scripts/mark_non_eu_urls_skipped.py

Safety:
    - Uses batch updates for performance
    - Provides progress updates
    - Can be interrupted with Ctrl+C
    - Confirms before proceeding
"""

import sys
from datetime import datetime, timezone
from pathlib import Path

# Add parent directory to path to import src modules
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.database import SessionLocal
from src.models.url import URL, URLStatus


def confirm_action(url_count: int) -> bool:
    """Ask user to confirm the action.

    Args:
        url_count: Number of URLs that will be marked as SKIPPED

    Returns:
        True if user confirms, False otherwise
    """
    print("\n" + "=" * 60)
    print("WARNING: This will mark URLs as SKIPPED")
    print("=" * 60)
    print(f"URLs to be marked: {url_count:,}")
    print("Status change: PENDING → SKIPPED")
    print('Error message: "Filtered: Non-EU language"')
    print("=" * 60)

    response = input("\nProceed with marking URLs as SKIPPED? (yes/no): ").strip().lower()
    return response in ["yes", "y"]


def mark_urls_skipped_batch(db, url_ids: list[int], batch_size: int = 1000) -> None:
    """Mark URLs as SKIPPED in batches.

    Args:
        db: Database session
        url_ids: List of URL IDs to mark as SKIPPED
        batch_size: Number of URLs to update per batch
    """
    total = len(url_ids)
    updated_count = 0

    print("\nMarking URLs as SKIPPED...")

    for i in range(0, total, batch_size):
        batch = url_ids[i : i + batch_size]

        try:
            # Update batch
            result = (
                db.query(URL)
                .filter(URL.id.in_(batch))
                .update(
                    {
                        "status": URLStatus.SKIPPED,
                        "error_message": "Filtered: Non-EU language",
                        "updated_at": datetime.now(timezone.utc),
                    },
                    synchronize_session=False,
                )
            )
            db.commit()

            updated_count += result
            processed = min(i + batch_size, total)
            percent = (processed / total) * 100
            print(f"Progress: {processed:,}/{total:,} ({percent:.1f}%) - Updated: {updated_count:,}")

        except Exception as e:
            print(f"\nERROR updating batch {i}-{i+batch_size}: {e}")
            db.rollback()
            raise

    print(f"\n✓ Successfully updated {updated_count:,} URLs")


def main() -> None:
    """Main function to read URL IDs and mark them as SKIPPED."""
    input_file = "/tmp/non_eu_urls.txt"

    # Check if input file exists
    if not Path(input_file).exists():
        print(f"ERROR: Input file not found: {input_file}")
        print("\nPlease run the analysis script first:")
        print("  python scripts/analyze_url_languages.py")
        sys.exit(1)

    # Read URL IDs from file
    print(f"Reading URL IDs from {input_file}...")
    with open(input_file) as f:
        url_ids = [int(line.strip()) for line in f if line.strip()]

    if not url_ids:
        print("ERROR: No URL IDs found in the input file.")
        sys.exit(1)

    print(f"Found {len(url_ids):,} URL IDs to mark as SKIPPED")

    # Confirm action
    if not confirm_action(len(url_ids)):
        print("\nOperation cancelled by user.")
        sys.exit(0)

    # Connect to database
    print("\nConnecting to database...")
    db = SessionLocal()

    try:
        # Mark URLs as SKIPPED
        mark_urls_skipped_batch(db, url_ids, batch_size=1000)

        # Verify results
        print("\nVerifying results...")
        skipped_count = db.query(URL).filter(URL.status == URLStatus.SKIPPED).count()
        pending_count = db.query(URL).filter(URL.status == URLStatus.PENDING).count()

        print("\n" + "=" * 60)
        print("CLEANUP COMPLETE")
        print("=" * 60)
        print(f"Total SKIPPED URLs: {skipped_count:,}")
        print(f"Remaining PENDING URLs: {pending_count:,}")
        print("=" * 60)

        print("\nNext steps:")
        print("1. Verify the crawler is using language filtering")
        print("2. Monitor crawler logs for filtering statistics")
        print("3. Check that EU content is still being indexed properly")

    except KeyboardInterrupt:
        print("\n\nInterrupted by user. Rolling back...")
        db.rollback()
        sys.exit(1)

    except Exception as e:
        print(f"\n\nERROR: {e}")
        db.rollback()
        import traceback

        traceback.print_exc()
        sys.exit(1)

    finally:
        db.close()


if __name__ == "__main__":
    main()
